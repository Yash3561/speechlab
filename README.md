<div align="center">

# ğŸ™ï¸ SpeechLab

### Speech Model Training Infrastructure

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.1+-ee4c2c.svg)](https://pytorch.org)
[![Ray](https://img.shields.io/badge/Ray-2.9+-028cf0.svg)](https://ray.io)
[![Next.js](https://img.shields.io/badge/Next.js-14-black.svg)](https://nextjs.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

*A distributed ML pipeline for training and evaluating speech recognition models â€” built with Ray, PyTorch, and MLOps best practices.*

[**Live Demo**](#demo) Â· [**Documentation**](#documentation) Â· [**Quick Start**](#-quick-start)

</div>

---

## ğŸ¯ What is SpeechLab?

SpeechLab is a **full-stack training and evaluation infrastructure** for speech models. It provides:

- ğŸš€ **Distributed Training** â€” Multi-GPU/multi-node training with Ray Train
- ğŸ“Š **Experiment Tracking** â€” Full reproducibility with MLflow
- ğŸ“ˆ **Real-Time Monitoring** â€” Live training dashboard with WebSocket updates
- ğŸ¯ **Multi-Metric Evaluation** â€” WER, CER, RTF with regression detection
- âš™ï¸ **Config-Driven** â€” Change experiments via YAML, not code

---

## ğŸ–¼ï¸ Dashboard Preview

<div align="center">
<img src="docs/dashboard-preview.png" alt="SpeechLab Dashboard" width="800"/>
</div>

> Real-time training metrics, experiment management, and system monitoring â€” all in one beautiful interface.

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10+
- Node.js 18+
- Docker & Docker Compose (optional, for services)

### Installation

```bash
# Clone the repository
git clone https://github.com/Yash3561/speechlab.git
cd speechlab

# Option 1: Run setup script (Windows)
.\setup.bat

# Option 2: Manual setup
python -m venv .venv
.venv\Scripts\activate  # Windows
pip install -e ".[dev]"

cd frontend && npm install && cd ..
```

### Start the Application

```bash
# Terminal 1: Start backend API
.venv\Scripts\activate
uvicorn backend.api.main:app --reload --port 8000

# Terminal 2: Start frontend
cd frontend
npm run dev

# Open http://localhost:3000
```

### (Optional) Start Docker Services

```bash
docker-compose up -d
# PostgreSQL: localhost:5432
# Redis: localhost:6379
# MinIO: localhost:9000
# MLflow: localhost:5000
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       SpeechLab                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Frontend   â”‚â”€â”€â”€â–¶â”‚   FastAPI   â”‚â”€â”€â”€â–¶â”‚    Ray      â”‚     â”‚
â”‚  â”‚  (Next.js)  â”‚â—€â”€â”€â”€â”‚   Backend   â”‚â—€â”€â”€â”€â”‚   Cluster   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚         â”‚                  â”‚                  â”‚             â”‚
â”‚         â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”          â”‚             â”‚
â”‚         â”‚           â–¼             â–¼          â–¼             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  WebSocket  â”‚ â”‚Postgresâ”‚ â”‚ Redis  â”‚ â”‚ MLflow â”‚         â”‚
â”‚  â”‚  (Metrics)  â”‚ â”‚        â”‚ â”‚        â”‚ â”‚        â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
speechlab/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/              # FastAPI endpoints
â”‚   â”‚   â”œâ”€â”€ main.py       # App entry point
â”‚   â”‚   â””â”€â”€ endpoints/    # Route handlers
â”‚   â”œâ”€â”€ core/             # Config, logging, utils
â”‚   â”œâ”€â”€ data/             # Audio processing pipeline
â”‚   â”‚   â”œâ”€â”€ dataset.py    # Data loading
â”‚   â”‚   â”œâ”€â”€ features.py   # Feature extraction
â”‚   â”‚   â””â”€â”€ augmentation.py
â”‚   â”œâ”€â”€ training/         # Training infrastructure
â”‚   â”‚   â”œâ”€â”€ trainer.py    # Training loop
â”‚   â”‚   â””â”€â”€ models.py     # Model registry
â”‚   â””â”€â”€ evaluation/       # Metrics & evaluation
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app/              # Next.js pages
â”‚   â”œâ”€â”€ components/       # React components
â”‚   â””â”€â”€ lib/              # Utilities
â”œâ”€â”€ configs/              # Experiment configs (YAML)
â”œâ”€â”€ scripts/              # CLI tools
â”œâ”€â”€ tests/                # Unit tests
â””â”€â”€ docker-compose.yml    # Infrastructure
```

---

## ğŸ§ª Running Experiments

### Via CLI

```bash
# Activate environment
.venv\Scripts\activate

# Run training
python scripts/train.py --config configs/experiments/demo_whisper_tiny.yaml

# Dry run (validate config)
python scripts/train.py --config configs/experiments/demo_whisper_tiny.yaml --dry-run
```

### Example Config

```yaml
experiment:
  name: "whisper_tiny_demo"
  
model:
  architecture: "whisper"
  variant: "tiny"
  
training:
  max_epochs: 5
  batch_size: 8
  learning_rate: 0.0001
  mixed_precision: true
  gradient_accumulation_steps: 4
```

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|-------|------------|
| **Orchestration** | Ray 2.9+ (Train, Data, Tune) |
| **ML Framework** | PyTorch 2.1+ with TorchAudio |
| **API** | FastAPI (async, WebSocket) |
| **Experiment Tracking** | MLflow |
| **Frontend** | Next.js 14, Tailwind CSS |
| **Database** | PostgreSQL (Supabase) |
| **Cache/Queue** | Redis (Upstash) |
| **Storage** | S3-compatible (Cloudflare R2) |

---

## ğŸ“ Why This Architecture?

This project demonstrates **solid ML engineering patterns**:

1. **Separation of Concerns** â€” Data, training, evaluation are independent modules
2. **Scalability** â€” Ray enables distributed computing across GPUs/nodes
3. **Reproducibility** â€” Every experiment is tracked and versioned via MLflow
4. **Observability** â€” Real-time monitoring with WebSocket streaming
5. **Flexibility** â€” Config-driven, architecture-agnostic design

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

---

## ğŸ“„ License

This project is licensed under the MIT License â€” see the [LICENSE](LICENSE) file for details.

---

<div align="center">

**Built with â¤ï¸ for the ML community**

</div>
